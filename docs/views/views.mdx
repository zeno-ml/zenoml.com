# Instance views

Zeno Instance Views are modular renderers for different data types and tasks.
Each of the following views can be passed as the `view` option to a TOML configuration file. To create a new or custom view see [Creating a view](/docs/views/new-view)

<table>
  <tr>
    <th>View Name</th>
    <th>Description</th>
  </tr>
  <tr>
    <td>image-classification</td>
    <td>
      Display images with ground truth and predicted class labels. Works for both binary
      and multiclass classification. Requires image inputs and text or numeric outputs.
    </td>
  </tr>
  <tr>
    <td>text-classification</td>
    <td>
      Display text with ground truth and predicted class labels. Requires text inputs
      and text or numeric outputs.
    </td>
  </tr>
  <tr>
    <td>audio-transcription</td>
    <td>
      Display audio file along with outputed text, e.g. transcription. Requires audio
      inputs and text outputs.
    </td>
  </tr>
  <tr>
    <td>image-segmentation</td>
    <td>
      Display image with overlayed ground truth and predicted segmentation masks. Works
      for both binary segmentation. Requires image inputs and binary image outputs.
    </td>
  </tr>
  <tr>
    <td>code-generation</td>
    <td>
      Show formatted code input and code predictions. Use for evaluating code generation
      models such as Codex.
    </td>
  </tr>
  <tr>
    <td>openai-chat</td>
    <td>
      Show input-output pairs from chatbot models using the OpenAI API. See the{" "}
      <a href="https://platform.openai.com/docs/guides/chat">API documentation</a> for
      details on the required Chat data format.
    </td>
  </tr>
  <tr>
    <td>chatbot</td>
    <td>Show a single input-output pair from chatbot models.</td>
  </tr>
</table>
