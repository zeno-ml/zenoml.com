"use strict";(self.webpackChunkzeno_docs=self.webpackChunkzeno_docs||[]).push([[206],{9568:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>c});var a=n(7462),o=(n(7294),n(3905));n(614);const i={sidebar_position:1},r="Getting Started",s={unversionedId:"intro",id:"intro",title:"Getting Started",description:"Zeno is an interactive platform for AI evaluation for exploring, discovering and reporting the performance of your models.",source:"@site/docs/intro.mdx",sourceDirName:".",slug:"/intro",permalink:"/docs/intro",draft:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",next:{title:"Python Client API",permalink:"/docs/python-client"}},l={},c=[{value:"Creating a Project",id:"creating-a-project",level:2},{value:"Complete Example",id:"complete-example",level:4},{value:"Quickstart with Zeno Build",id:"quickstart-with-zeno-build",level:2}],p={toc:c},d="wrapper";function u(e){let{components:t,...n}=e;return(0,o.kt)(d,(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"getting-started"},"Getting Started"),(0,o.kt)("p",null,"Zeno is an ",(0,o.kt)("strong",{parentName:"p"},"interactive platform for AI evaluation")," for exploring, discovering and reporting the performance of your models.\nUse it for any data type or task with Zeno's ",(0,o.kt)("a",{parentName:"p",href:"/docs/views/"},"modular views")," for everything from object detection to audio transcription and chatbot conversations.\nZeno helps you move beyond aggregate metrics and spot-checking model outputs to develop a deep and quantitative understanding of how your model behaves."),(0,o.kt)("p",null,"To get an idea of Zeno's features, you can explore public projects and reports in ",(0,o.kt)("a",{parentName:"p",href:"https://hub.zenoml.com"},"Zeno Hub"),".\nFor example, take a look at a ",(0,o.kt)("a",{parentName:"p",href:"https://hub.zenoml.com/report/cabreraalex/GPT%20MT%20Benchmark%20Report"},"report evaluating how well LLMs like GPT-4 do on language translation"),", along with the ",(0,o.kt)("a",{parentName:"p",href:"https://hub.zenoml.com/project/cabreraalex/GPT%20MT%20Benchmark/explore"},"underlying data used to create the report."),"."),(0,o.kt)("p",null,"Check out the ",(0,o.kt)("a",{parentName:"p",href:"/docs/using-zeno/"},"Using Zeno")," section for more information on how to use Zeno to evaluate your models."),(0,o.kt)("h2",{id:"creating-a-project"},"Creating a Project"),(0,o.kt)("p",null,"To create your own projects and reports, first create an account on ",(0,o.kt)("a",{parentName:"p",href:"https://hub.zenoml.com/signup"},"Zeno Hub"),".\nAfter logging in to Zeno Hub, generate your API key by clicking on your profile at the bottom left to navigate to your ",(0,o.kt)("a",{parentName:"p",href:"https://hub.zenoml.com/account"},"account page"),"."),(0,o.kt)("p",null,"Next, install the ",(0,o.kt)("inlineCode",{parentName:"p"},"zeno-client")," Python package, which is used to upload new datasets and AI system outputs:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"pip install zeno-client\n")),(0,o.kt)("p",null,"In a Python script or notebook we can now create a new project:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from zeno_client import ZenoClient\n\nclient = ZenoClient("YOUR API KEY HERE")\n')),(0,o.kt)("p",null,"Now lets load some text data to analyze. The client API works with Pandas DataFrames, so we can create a sample DataFrame looking at text sentiment classification:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from zeno_client import ZenoClient\n# highlight-next-line\nimport pandas as pd\n\nclient = ZenoClient("YOUR API KEY HERE")\n\n# highlight-start\ndf = pd.DataFrame(\n    {\n        "text": [\n            "I love this movie!",\n            "I hate this movie!",\n            "This movie is ok.",\n        ],\n        "label": ["positive", "negative", "neutral"],\n    }\n)\n\n# Explicitly save the index as a column to upload.\ndf["id"] = df.index\n\n# Add any additional columns you want to do analysis across.\ndf["input length"] = df["text"].str.len()\n\n# highlight-end\n')),(0,o.kt)("p",null,"Let's create a project for this task. ",(0,o.kt)("strong",{parentName:"p"},"Projects")," in Zeno are a base dataset and any number of AI system outputs, and are used to evaluate and compare AI system performance. Here we create a project and upload our base dataset."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from zeno_client import ZenoClient, ZenoMetric\n\n...\n\nproject = client.create_project(\n    "Sentiment Classification",\n    "text-classification",\n    metrics=[\n        ZenoMetric(name="accuracy", type="mean", columns=["correct"]),\n    ]\n)\n\nproject.upload_dataset(df, id_column="id", label_column="label", data_column=\'text\')\n')),(0,o.kt)("p",null,'We named our project "Sentiment Classification" and specified that it is a text classification task.\nCheck out all supported data types and tasks ',(0,o.kt)("a",{parentName:"p",href:"https://zenoml.com/docs/views/"},"here"),".\nWe also added an initial accuracy metric which takes the mean of the ",(0,o.kt)("inlineCode",{parentName:"p"},"correct")," column, which will be present in the system outputs we upload later."),(0,o.kt)("p",null,"Next, we can upload some system outputs to evaluate. Here we'll upload some fake predictions from a model:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\n...\n\ndf_system = pd.DataFrame(\n    {\n        "output": ["positive", "negative", "negative"],\n    }\n)\n\n# Create an id column to match the base dataset.\ndf_system["id"] = df_system.index\n\n# Measure accuracy for each instance, which is averaged by the ZenoMetric above.\ndf_system["correct"] = (df_system["output"] == df["label"]).astype(int)\n\nproj.upload_system("System A", df_system, output_column="output", id_column="id")\n')),(0,o.kt)("p",null,"You can now navigate to the project URL in Zeno Hub to see the uploaded data and metrics and start exploring your AI system's performance!"),(0,o.kt)("h4",{id:"complete-example"},"Complete Example"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from zeno_client import ZenoClient, ZenoMetric\nimport pandas as pd\n\nclient = ZenoClient("YOUR API KEY HERE")\n\ndf = pd.DataFrame(\n    {\n        "text": [\n            "I love this movie!",\n            "I hate this movie!",\n            "This movie is ok.",\n        ],\n        "label": ["positive", "negative", "neutral"],\n    }\n)\n\n# Explicitly save the index as a column to upload.\ndf["id"] = df.index\n\n# Add any additional columns you want to do analysis across.\ndf["input length"] = df["text"].str.len()\n\nproject = client.create_project(\n    "Sentiment Classification",\n    "text-classification",\n    metrics=[\n        ZenoMetric(name="accuracy", type="mean", columns=["correct"]),\n    ]\n)\n\nproject.upload_dataset(df, id_column="id", label_column="label", data_column=\'text\')\n\ndf_system = pd.DataFrame(\n    {\n        "output": ["positive", "negative", "negative"],\n    }\n)\n\n# Create an id column to match the base dataset.\ndf_system["id"] = df_system.index\n\n# Measure accuracy for each instance, which is averaged by the ZenoMetric above.\ndf_system["correct"] = (df_system["output"] == df["label"]).astype(int)\n\nproject.upload_system("System A", df_system, output_column="output", id_column="id")\n')),(0,o.kt)("h2",{id:"quickstart-with-zeno-build"},"Quickstart with Zeno Build"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/zeno-ml/zeno-build"},"Zeno Build")," is a Python library that makes it easy to set up Zeno projects for common AI and ML tasks."),(0,o.kt)("p",null,"Follow the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/zeno-ml/zeno-build/tree/main/docs/tutorial"},"Zeno Build Tutorial")," to learn the basic Zeno concepts on an example LLM task."))}u.isMDXComponent=!0}}]);